{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Borris\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 600)               480600    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                6010      \n",
      "=================================================================\n",
      "Total params: 1,114,610\n",
      "Trainable params: 1,114,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/25\n",
      " - 12s - loss: 1.2604 - acc: 0.6975 - val_loss: 0.6640 - val_acc: 0.8577\n",
      "Epoch 2/25\n",
      " - 11s - loss: 0.5647 - acc: 0.8627 - val_loss: 0.4415 - val_acc: 0.8877\n",
      "Epoch 3/25\n",
      " - 11s - loss: 0.4317 - acc: 0.8869 - val_loss: 0.3686 - val_acc: 0.9027\n",
      "Epoch 4/25\n",
      " - 11s - loss: 0.3746 - acc: 0.8988 - val_loss: 0.3322 - val_acc: 0.9093\n",
      "Epoch 5/25\n",
      " - 11s - loss: 0.3412 - acc: 0.9053 - val_loss: 0.3071 - val_acc: 0.9157\n",
      "Epoch 6/25\n",
      " - 11s - loss: 0.3177 - acc: 0.9124 - val_loss: 0.2906 - val_acc: 0.9205\n",
      "Epoch 7/25\n",
      " - 12s - loss: 0.2999 - acc: 0.9165 - val_loss: 0.2759 - val_acc: 0.9238\n",
      "Epoch 8/25\n",
      " - 13s - loss: 0.2856 - acc: 0.9199 - val_loss: 0.2647 - val_acc: 0.9270\n",
      "Epoch 9/25\n",
      " - 12s - loss: 0.2731 - acc: 0.9237 - val_loss: 0.2550 - val_acc: 0.9295\n",
      "Epoch 10/25\n",
      " - 13s - loss: 0.2625 - acc: 0.9262 - val_loss: 0.2468 - val_acc: 0.9314\n",
      "Epoch 11/25\n",
      " - 13s - loss: 0.2528 - acc: 0.9294 - val_loss: 0.2400 - val_acc: 0.9322\n",
      "Epoch 12/25\n",
      " - 12s - loss: 0.2443 - acc: 0.9314 - val_loss: 0.2323 - val_acc: 0.9357\n",
      "Epoch 13/25\n",
      " - 13s - loss: 0.2364 - acc: 0.9334 - val_loss: 0.2258 - val_acc: 0.9380\n",
      "Epoch 14/25\n",
      " - 12s - loss: 0.2292 - acc: 0.9361 - val_loss: 0.2192 - val_acc: 0.9391\n",
      "Epoch 15/25\n",
      " - 12s - loss: 0.2223 - acc: 0.9374 - val_loss: 0.2146 - val_acc: 0.9412\n",
      "Epoch 16/25\n",
      " - 13s - loss: 0.2157 - acc: 0.9395 - val_loss: 0.2099 - val_acc: 0.9418\n",
      "Epoch 17/25\n",
      " - 14s - loss: 0.2100 - acc: 0.9409 - val_loss: 0.2050 - val_acc: 0.9429\n",
      "Epoch 18/25\n",
      " - 13s - loss: 0.2043 - acc: 0.9425 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 19/25\n",
      " - 12s - loss: 0.1989 - acc: 0.9440 - val_loss: 0.1952 - val_acc: 0.9465\n",
      "Epoch 20/25\n",
      " - 13s - loss: 0.1936 - acc: 0.9452 - val_loss: 0.1912 - val_acc: 0.9483\n",
      "Epoch 21/25\n",
      " - 12s - loss: 0.1889 - acc: 0.9470 - val_loss: 0.1872 - val_acc: 0.9484\n",
      "Epoch 22/25\n",
      " - 12s - loss: 0.1842 - acc: 0.9484 - val_loss: 0.1841 - val_acc: 0.9487\n",
      "Epoch 23/25\n",
      " - 11s - loss: 0.1799 - acc: 0.9492 - val_loss: 0.1807 - val_acc: 0.9503\n",
      "Epoch 24/25\n",
      " - 13s - loss: 0.1756 - acc: 0.9504 - val_loss: 0.1775 - val_acc: 0.9515\n",
      "Epoch 25/25\n",
      " - 14s - loss: 0.1715 - acc: 0.9513 - val_loss: 0.1736 - val_acc: 0.9523\n",
      "Точность работы на тестовых данных: 94.98%\n"
     ]
    }
   ],
   "source": [
    "#распознавание рукописного текста\n",
    "import numpy\n",
    "from keras.datasets import mnist#-классификация рукописных цифр\n",
    "from keras.models import Sequential#модель нейронной сети слои которой соединены друг с другом\n",
    "from keras.layers import Dense#соединение всех нейронов предыдущего уровня со всми нейронами следующего уровня\n",
    "from keras.utils import np_utils#утилиты для работы с массивами\n",
    "\n",
    "# Устанавливаем seed для повторяемости результатов\n",
    "numpy.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Преобразование размерности изображений\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "# Нормализация данных\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "\n",
    "# Добавляем два уровня сети\n",
    "#Вход - 800 нейронов, у каждого нейрона 784 входа(количество пикселов во входном изображении)\n",
    "#инициализируются случайно с помощью нормального распределения\n",
    "model.add(Dense(800, input_dim=784, activation=\"relu\", kernel_initializer=\"normal\"))\n",
    "\n",
    "#Внутренний слой\n",
    "model.add(Dense(600, activation=\"relu\", kernel_initializer=\"normal\"))\n",
    "\n",
    "#Выход - 10 нейронов  - распознанные цифры от 0 до 9 \n",
    "#инициализируются случайно с помощью нормального распределения\n",
    "model.add(Dense(10, activation=\"softmax\", kernel_initializer=\"normal\"))\n",
    "#activation=\"softmax\" - применяется, если в качестве выходных значений используется вероятность\n",
    "\n",
    "# Компилируем модель\n",
    "#SGD - стохастический градиентный спуск\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Обучаем сеть\n",
    "# размер минивыборки = 200 элементов, 25 = количество обучений(лучший результат при 150)\n",
    "#20% - проверочная выборка\n",
    "model.fit(X_train, Y_train, batch_size=200, epochs=25, validation_split=0.2, verbose=2)\n",
    "\n",
    "# Оцениваем качество обучения сети на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
