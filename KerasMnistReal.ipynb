{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 75)        1950      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 75)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 12, 12, 75)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 100)         187600    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               800500    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 995,060\n",
      "Trainable params: 995,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/150\n",
      " - 219s - loss: 1.9364 - acc: 0.3673 - val_loss: 0.8844 - val_acc: 0.8217\n",
      "Epoch 2/150\n",
      " - 218s - loss: 0.7609 - acc: 0.7596 - val_loss: 0.3654 - val_acc: 0.8956\n",
      "Epoch 3/150\n",
      " - 218s - loss: 0.4888 - acc: 0.8486 - val_loss: 0.2702 - val_acc: 0.9224\n",
      "Epoch 4/150\n",
      " - 211s - loss: 0.3823 - acc: 0.8819 - val_loss: 0.2166 - val_acc: 0.9380\n",
      "Epoch 5/150\n",
      " - 212s - loss: 0.3223 - acc: 0.9017 - val_loss: 0.1852 - val_acc: 0.9474\n",
      "Epoch 6/150\n",
      " - 210s - loss: 0.2792 - acc: 0.9141 - val_loss: 0.1645 - val_acc: 0.9513\n",
      "Epoch 7/150\n",
      " - 209s - loss: 0.2526 - acc: 0.9241 - val_loss: 0.1469 - val_acc: 0.9567\n",
      "Epoch 8/150\n",
      " - 210s - loss: 0.2280 - acc: 0.9296 - val_loss: 0.1336 - val_acc: 0.9602\n",
      "Epoch 9/150\n",
      " - 212s - loss: 0.2079 - acc: 0.9379 - val_loss: 0.1227 - val_acc: 0.9636\n",
      "Epoch 10/150\n",
      " - 222s - loss: 0.1915 - acc: 0.9412 - val_loss: 0.1146 - val_acc: 0.9648\n",
      "Epoch 11/150\n",
      " - 211s - loss: 0.1837 - acc: 0.9440 - val_loss: 0.1094 - val_acc: 0.9671\n",
      "Epoch 12/150\n",
      " - 199s - loss: 0.1703 - acc: 0.9482 - val_loss: 0.1018 - val_acc: 0.9693\n",
      "Epoch 13/150\n",
      " - 199s - loss: 0.1617 - acc: 0.9500 - val_loss: 0.0969 - val_acc: 0.9707\n",
      "Epoch 14/150\n",
      " - 199s - loss: 0.1543 - acc: 0.9533 - val_loss: 0.0943 - val_acc: 0.9713\n",
      "Epoch 15/150\n",
      " - 198s - loss: 0.1479 - acc: 0.9544 - val_loss: 0.0889 - val_acc: 0.9736\n",
      "Epoch 16/150\n",
      " - 198s - loss: 0.1407 - acc: 0.9569 - val_loss: 0.0860 - val_acc: 0.9736\n",
      "Epoch 17/150\n",
      " - 199s - loss: 0.1362 - acc: 0.9587 - val_loss: 0.0829 - val_acc: 0.9753\n",
      "Epoch 18/150\n",
      " - 199s - loss: 0.1325 - acc: 0.9587 - val_loss: 0.0802 - val_acc: 0.9762\n",
      "Epoch 19/150\n",
      " - 198s - loss: 0.1252 - acc: 0.9623 - val_loss: 0.0775 - val_acc: 0.9763\n",
      "Epoch 20/150\n",
      " - 199s - loss: 0.1239 - acc: 0.9617 - val_loss: 0.0757 - val_acc: 0.9769\n",
      "Epoch 21/150\n",
      " - 198s - loss: 0.1185 - acc: 0.9634 - val_loss: 0.0741 - val_acc: 0.9775\n",
      "Epoch 22/150\n",
      " - 198s - loss: 0.1173 - acc: 0.9645 - val_loss: 0.0728 - val_acc: 0.9779\n",
      "Epoch 23/150\n",
      " - 200s - loss: 0.1143 - acc: 0.9646 - val_loss: 0.0711 - val_acc: 0.9787\n",
      "Epoch 24/150\n",
      " - 198s - loss: 0.1088 - acc: 0.9664 - val_loss: 0.0698 - val_acc: 0.9784\n",
      "Epoch 25/150\n",
      " - 198s - loss: 0.1061 - acc: 0.9673 - val_loss: 0.0685 - val_acc: 0.9788\n",
      "Epoch 26/150\n",
      " - 199s - loss: 0.1051 - acc: 0.9678 - val_loss: 0.0676 - val_acc: 0.9795\n",
      "Epoch 27/150\n",
      " - 202s - loss: 0.1012 - acc: 0.9687 - val_loss: 0.0658 - val_acc: 0.9795\n",
      "Epoch 28/150\n",
      " - 204s - loss: 0.1004 - acc: 0.9685 - val_loss: 0.0643 - val_acc: 0.9802\n",
      "Epoch 29/150\n",
      " - 199s - loss: 0.0986 - acc: 0.9687 - val_loss: 0.0644 - val_acc: 0.9797\n",
      "Epoch 30/150\n",
      " - 199s - loss: 0.0956 - acc: 0.9705 - val_loss: 0.0630 - val_acc: 0.9804\n",
      "Epoch 31/150\n",
      " - 199s - loss: 0.0937 - acc: 0.9704 - val_loss: 0.0612 - val_acc: 0.9808\n",
      "Epoch 32/150\n",
      " - 199s - loss: 0.0934 - acc: 0.9706 - val_loss: 0.0608 - val_acc: 0.9811\n",
      "Epoch 33/150\n",
      " - 199s - loss: 0.0914 - acc: 0.9713 - val_loss: 0.0596 - val_acc: 0.9813\n",
      "Epoch 34/150\n",
      " - 198s - loss: 0.0874 - acc: 0.9732 - val_loss: 0.0595 - val_acc: 0.9818\n",
      "Epoch 35/150\n",
      " - 198s - loss: 0.0882 - acc: 0.9726 - val_loss: 0.0585 - val_acc: 0.9818\n",
      "Epoch 36/150\n",
      " - 198s - loss: 0.0844 - acc: 0.9735 - val_loss: 0.0571 - val_acc: 0.9823\n",
      "Epoch 37/150\n",
      " - 198s - loss: 0.0842 - acc: 0.9741 - val_loss: 0.0570 - val_acc: 0.9824\n",
      "Epoch 38/150\n",
      " - 199s - loss: 0.0834 - acc: 0.9738 - val_loss: 0.0569 - val_acc: 0.9826\n",
      "Epoch 39/150\n",
      " - 198s - loss: 0.0805 - acc: 0.9750 - val_loss: 0.0556 - val_acc: 0.9828\n",
      "Epoch 40/150\n",
      " - 198s - loss: 0.0805 - acc: 0.9755 - val_loss: 0.0555 - val_acc: 0.9831\n",
      "Epoch 41/150\n",
      " - 199s - loss: 0.0819 - acc: 0.9742 - val_loss: 0.0555 - val_acc: 0.9828\n",
      "Epoch 42/150\n",
      " - 198s - loss: 0.0780 - acc: 0.9756 - val_loss: 0.0540 - val_acc: 0.9836\n",
      "Epoch 43/150\n",
      " - 198s - loss: 0.0773 - acc: 0.9762 - val_loss: 0.0531 - val_acc: 0.9839\n",
      "Epoch 44/150\n",
      " - 199s - loss: 0.0764 - acc: 0.9764 - val_loss: 0.0528 - val_acc: 0.9841\n",
      "Epoch 45/150\n",
      " - 198s - loss: 0.0772 - acc: 0.9759 - val_loss: 0.0522 - val_acc: 0.9846\n",
      "Epoch 46/150\n",
      " - 198s - loss: 0.0758 - acc: 0.9763 - val_loss: 0.0524 - val_acc: 0.9845\n",
      "Epoch 47/150\n",
      " - 198s - loss: 0.0735 - acc: 0.9769 - val_loss: 0.0509 - val_acc: 0.9847\n",
      "Epoch 48/150\n",
      " - 198s - loss: 0.0722 - acc: 0.9778 - val_loss: 0.0509 - val_acc: 0.9847\n",
      "Epoch 49/150\n",
      " - 199s - loss: 0.0717 - acc: 0.9774 - val_loss: 0.0508 - val_acc: 0.9849\n",
      "Epoch 50/150\n",
      " - 198s - loss: 0.0705 - acc: 0.9783 - val_loss: 0.0494 - val_acc: 0.9854\n",
      "Epoch 51/150\n",
      " - 198s - loss: 0.0703 - acc: 0.9776 - val_loss: 0.0498 - val_acc: 0.9854\n",
      "Epoch 52/150\n",
      " - 198s - loss: 0.0689 - acc: 0.9785 - val_loss: 0.0497 - val_acc: 0.9856\n",
      "Epoch 53/150\n",
      " - 199s - loss: 0.0676 - acc: 0.9785 - val_loss: 0.0481 - val_acc: 0.9863\n",
      "Epoch 54/150\n",
      " - 198s - loss: 0.0679 - acc: 0.9785 - val_loss: 0.0474 - val_acc: 0.9863\n",
      "Epoch 55/150\n",
      " - 198s - loss: 0.0673 - acc: 0.9793 - val_loss: 0.0480 - val_acc: 0.9857\n",
      "Epoch 56/150\n",
      " - 199s - loss: 0.0656 - acc: 0.9795 - val_loss: 0.0469 - val_acc: 0.9864\n",
      "Epoch 57/150\n",
      " - 198s - loss: 0.0652 - acc: 0.9798 - val_loss: 0.0471 - val_acc: 0.9862\n",
      "Epoch 58/150\n",
      " - 198s - loss: 0.0645 - acc: 0.9795 - val_loss: 0.0471 - val_acc: 0.9865\n",
      "Epoch 59/150\n",
      " - 199s - loss: 0.0659 - acc: 0.9788 - val_loss: 0.0463 - val_acc: 0.9865\n",
      "Epoch 60/150\n",
      " - 198s - loss: 0.0638 - acc: 0.9805 - val_loss: 0.0460 - val_acc: 0.9863\n",
      "Epoch 61/150\n",
      " - 198s - loss: 0.0643 - acc: 0.9795 - val_loss: 0.0461 - val_acc: 0.9866\n",
      "Epoch 62/150\n",
      " - 198s - loss: 0.0631 - acc: 0.9805 - val_loss: 0.0452 - val_acc: 0.9870\n",
      "Epoch 63/150\n",
      " - 199s - loss: 0.0596 - acc: 0.9813 - val_loss: 0.0453 - val_acc: 0.9868\n",
      "Epoch 64/150\n",
      " - 198s - loss: 0.0609 - acc: 0.9807 - val_loss: 0.0448 - val_acc: 0.9868\n",
      "Epoch 65/150\n",
      " - 203s - loss: 0.0588 - acc: 0.9823 - val_loss: 0.0444 - val_acc: 0.9871\n",
      "Epoch 66/150\n",
      " - 198s - loss: 0.0615 - acc: 0.9809 - val_loss: 0.0443 - val_acc: 0.9873\n",
      "Epoch 67/150\n",
      " - 198s - loss: 0.0579 - acc: 0.9817 - val_loss: 0.0443 - val_acc: 0.9870\n",
      "Epoch 68/150\n",
      " - 199s - loss: 0.0602 - acc: 0.9811 - val_loss: 0.0444 - val_acc: 0.9871\n",
      "Epoch 69/150\n",
      " - 198s - loss: 0.0574 - acc: 0.9820 - val_loss: 0.0436 - val_acc: 0.9871\n",
      "Epoch 70/150\n",
      " - 198s - loss: 0.0578 - acc: 0.9819 - val_loss: 0.0433 - val_acc: 0.9878\n",
      "Epoch 71/150\n",
      " - 199s - loss: 0.0565 - acc: 0.9823 - val_loss: 0.0433 - val_acc: 0.9874\n",
      "Epoch 72/150\n",
      " - 198s - loss: 0.0563 - acc: 0.9819 - val_loss: 0.0426 - val_acc: 0.9878\n",
      "Epoch 73/150\n",
      " - 198s - loss: 0.0565 - acc: 0.9823 - val_loss: 0.0429 - val_acc: 0.9871\n",
      "Epoch 74/150\n",
      " - 199s - loss: 0.0553 - acc: 0.9827 - val_loss: 0.0427 - val_acc: 0.9874\n",
      "Epoch 75/150\n",
      " - 198s - loss: 0.0567 - acc: 0.9819 - val_loss: 0.0431 - val_acc: 0.9871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/150\n",
      " - 198s - loss: 0.0540 - acc: 0.9834 - val_loss: 0.0416 - val_acc: 0.9880\n",
      "Epoch 77/150\n",
      " - 199s - loss: 0.0531 - acc: 0.9835 - val_loss: 0.0423 - val_acc: 0.9879\n",
      "Epoch 78/150\n",
      " - 198s - loss: 0.0528 - acc: 0.9836 - val_loss: 0.0416 - val_acc: 0.9879\n",
      "Epoch 79/150\n",
      " - 198s - loss: 0.0525 - acc: 0.9830 - val_loss: 0.0410 - val_acc: 0.9878\n",
      "Epoch 80/150\n",
      " - 198s - loss: 0.0537 - acc: 0.9829 - val_loss: 0.0416 - val_acc: 0.9878\n",
      "Epoch 81/150\n",
      " - 199s - loss: 0.0528 - acc: 0.9836 - val_loss: 0.0407 - val_acc: 0.9883\n",
      "Epoch 82/150\n",
      " - 198s - loss: 0.0515 - acc: 0.9837 - val_loss: 0.0403 - val_acc: 0.9883\n",
      "Epoch 83/150\n",
      " - 198s - loss: 0.0510 - acc: 0.9839 - val_loss: 0.0401 - val_acc: 0.9882\n",
      "Epoch 84/150\n",
      " - 199s - loss: 0.0512 - acc: 0.9846 - val_loss: 0.0399 - val_acc: 0.9883\n",
      "Epoch 85/150\n",
      " - 198s - loss: 0.0489 - acc: 0.9842 - val_loss: 0.0396 - val_acc: 0.9886\n",
      "Epoch 86/150\n",
      " - 198s - loss: 0.0500 - acc: 0.9843 - val_loss: 0.0400 - val_acc: 0.9882\n",
      "Epoch 87/150\n",
      " - 199s - loss: 0.0485 - acc: 0.9841 - val_loss: 0.0395 - val_acc: 0.9886\n",
      "Epoch 88/150\n",
      " - 198s - loss: 0.0480 - acc: 0.9847 - val_loss: 0.0388 - val_acc: 0.9886\n",
      "Epoch 89/150\n",
      " - 199s - loss: 0.0486 - acc: 0.9844 - val_loss: 0.0393 - val_acc: 0.9886\n",
      "Epoch 90/150\n",
      " - 198s - loss: 0.0488 - acc: 0.9849 - val_loss: 0.0391 - val_acc: 0.9885\n",
      "Epoch 91/150\n",
      " - 198s - loss: 0.0476 - acc: 0.9846 - val_loss: 0.0389 - val_acc: 0.9887\n",
      "Epoch 92/150\n",
      " - 199s - loss: 0.0493 - acc: 0.9842 - val_loss: 0.0391 - val_acc: 0.9888\n",
      "Epoch 93/150\n",
      " - 198s - loss: 0.0483 - acc: 0.9848 - val_loss: 0.0388 - val_acc: 0.9886\n",
      "Epoch 94/150\n",
      " - 200s - loss: 0.0471 - acc: 0.9857 - val_loss: 0.0379 - val_acc: 0.9886\n",
      "Epoch 95/150\n",
      " - 201s - loss: 0.0477 - acc: 0.9848 - val_loss: 0.0381 - val_acc: 0.9886\n",
      "Epoch 96/150\n",
      " - 201s - loss: 0.0463 - acc: 0.9852 - val_loss: 0.0383 - val_acc: 0.9884\n",
      "Epoch 97/150\n",
      " - 200s - loss: 0.0465 - acc: 0.9854 - val_loss: 0.0377 - val_acc: 0.9888\n",
      "Epoch 98/150\n",
      " - 198s - loss: 0.0463 - acc: 0.9853 - val_loss: 0.0378 - val_acc: 0.9890\n",
      "Epoch 99/150\n",
      " - 198s - loss: 0.0450 - acc: 0.9855 - val_loss: 0.0377 - val_acc: 0.9893\n",
      "Epoch 100/150\n",
      " - 198s - loss: 0.0447 - acc: 0.9859 - val_loss: 0.0380 - val_acc: 0.9888\n",
      "Epoch 101/150\n",
      " - 198s - loss: 0.0441 - acc: 0.9864 - val_loss: 0.0373 - val_acc: 0.9888\n",
      "Epoch 102/150\n",
      " - 204s - loss: 0.0451 - acc: 0.9851 - val_loss: 0.0372 - val_acc: 0.9889\n",
      "Epoch 103/150\n",
      " - 199s - loss: 0.0455 - acc: 0.9851 - val_loss: 0.0369 - val_acc: 0.9889\n",
      "Epoch 104/150\n",
      " - 199s - loss: 0.0443 - acc: 0.9858 - val_loss: 0.0367 - val_acc: 0.9891\n",
      "Epoch 105/150\n",
      " - 199s - loss: 0.0440 - acc: 0.9859 - val_loss: 0.0367 - val_acc: 0.9897\n",
      "Epoch 106/150\n",
      " - 199s - loss: 0.0458 - acc: 0.9860 - val_loss: 0.0370 - val_acc: 0.9888\n",
      "Epoch 107/150\n",
      " - 199s - loss: 0.0438 - acc: 0.9858 - val_loss: 0.0368 - val_acc: 0.9892\n",
      "Epoch 108/150\n",
      " - 198s - loss: 0.0436 - acc: 0.9865 - val_loss: 0.0363 - val_acc: 0.9891\n",
      "Epoch 109/150\n",
      " - 198s - loss: 0.0441 - acc: 0.9855 - val_loss: 0.0361 - val_acc: 0.9894\n",
      "Epoch 110/150\n",
      " - 198s - loss: 0.0425 - acc: 0.9863 - val_loss: 0.0361 - val_acc: 0.9892\n",
      "Epoch 111/150\n",
      " - 199s - loss: 0.0417 - acc: 0.9865 - val_loss: 0.0362 - val_acc: 0.9893\n",
      "Epoch 112/150\n",
      " - 198s - loss: 0.0422 - acc: 0.9869 - val_loss: 0.0363 - val_acc: 0.9888\n",
      "Epoch 113/150\n",
      " - 198s - loss: 0.0418 - acc: 0.9869 - val_loss: 0.0359 - val_acc: 0.9893\n",
      "Epoch 114/150\n",
      " - 198s - loss: 0.0420 - acc: 0.9868 - val_loss: 0.0363 - val_acc: 0.9891\n",
      "Epoch 115/150\n",
      " - 198s - loss: 0.0422 - acc: 0.9870 - val_loss: 0.0359 - val_acc: 0.9894\n",
      "Epoch 116/150\n",
      " - 198s - loss: 0.0392 - acc: 0.9878 - val_loss: 0.0358 - val_acc: 0.9893\n",
      "Epoch 117/150\n",
      " - 208s - loss: 0.0394 - acc: 0.9871 - val_loss: 0.0356 - val_acc: 0.9893\n",
      "Epoch 118/150\n",
      " - 204s - loss: 0.0399 - acc: 0.9869 - val_loss: 0.0360 - val_acc: 0.9898\n",
      "Epoch 119/150\n",
      " - 198s - loss: 0.0405 - acc: 0.9868 - val_loss: 0.0357 - val_acc: 0.9899\n",
      "Epoch 120/150\n",
      " - 198s - loss: 0.0395 - acc: 0.9875 - val_loss: 0.0356 - val_acc: 0.9896\n",
      "Epoch 121/150\n",
      " - 198s - loss: 0.0405 - acc: 0.9874 - val_loss: 0.0356 - val_acc: 0.9898\n",
      "Epoch 122/150\n",
      " - 198s - loss: 0.0389 - acc: 0.9878 - val_loss: 0.0354 - val_acc: 0.9893\n",
      "Epoch 123/150\n",
      " - 198s - loss: 0.0388 - acc: 0.9879 - val_loss: 0.0352 - val_acc: 0.9894\n",
      "Epoch 124/150\n",
      " - 198s - loss: 0.0405 - acc: 0.9871 - val_loss: 0.0352 - val_acc: 0.9898\n",
      "Epoch 125/150\n",
      " - 198s - loss: 0.0379 - acc: 0.9879 - val_loss: 0.0347 - val_acc: 0.9902\n",
      "Epoch 126/150\n",
      " - 199s - loss: 0.0393 - acc: 0.9871 - val_loss: 0.0346 - val_acc: 0.9898\n",
      "Epoch 127/150\n",
      " - 198s - loss: 0.0381 - acc: 0.9879 - val_loss: 0.0348 - val_acc: 0.9903\n",
      "Epoch 128/150\n",
      " - 198s - loss: 0.0378 - acc: 0.9882 - val_loss: 0.0340 - val_acc: 0.9901\n",
      "Epoch 129/150\n",
      " - 199s - loss: 0.0379 - acc: 0.9876 - val_loss: 0.0342 - val_acc: 0.9901\n",
      "Epoch 130/150\n",
      " - 199s - loss: 0.0378 - acc: 0.9881 - val_loss: 0.0341 - val_acc: 0.9905\n",
      "Epoch 131/150\n",
      " - 198s - loss: 0.0374 - acc: 0.9877 - val_loss: 0.0342 - val_acc: 0.9901\n",
      "Epoch 132/150\n",
      " - 198s - loss: 0.0373 - acc: 0.9880 - val_loss: 0.0346 - val_acc: 0.9903\n",
      "Epoch 133/150\n",
      " - 198s - loss: 0.0372 - acc: 0.9881 - val_loss: 0.0345 - val_acc: 0.9905\n",
      "Epoch 134/150\n",
      " - 198s - loss: 0.0371 - acc: 0.9886 - val_loss: 0.0346 - val_acc: 0.9904\n",
      "Epoch 135/150\n",
      " - 199s - loss: 0.0371 - acc: 0.9886 - val_loss: 0.0344 - val_acc: 0.9903\n",
      "Epoch 136/150\n",
      " - 198s - loss: 0.0362 - acc: 0.9881 - val_loss: 0.0342 - val_acc: 0.9898\n",
      "Epoch 137/150\n",
      " - 198s - loss: 0.0363 - acc: 0.9884 - val_loss: 0.0338 - val_acc: 0.9903\n",
      "Epoch 138/150\n",
      " - 198s - loss: 0.0372 - acc: 0.9884 - val_loss: 0.0335 - val_acc: 0.9904\n",
      "Epoch 139/150\n",
      " - 205s - loss: 0.0348 - acc: 0.9890 - val_loss: 0.0337 - val_acc: 0.9905\n",
      "Epoch 140/150\n",
      " - 198s - loss: 0.0368 - acc: 0.9881 - val_loss: 0.0343 - val_acc: 0.9903\n",
      "Epoch 141/150\n",
      " - 198s - loss: 0.0354 - acc: 0.9885 - val_loss: 0.0340 - val_acc: 0.9903\n",
      "Epoch 142/150\n",
      " - 198s - loss: 0.0362 - acc: 0.9884 - val_loss: 0.0337 - val_acc: 0.9905\n",
      "Epoch 143/150\n",
      " - 198s - loss: 0.0355 - acc: 0.9884 - val_loss: 0.0336 - val_acc: 0.9904\n",
      "Epoch 144/150\n",
      " - 198s - loss: 0.0344 - acc: 0.9889 - val_loss: 0.0335 - val_acc: 0.9905\n",
      "Epoch 145/150\n",
      " - 198s - loss: 0.0355 - acc: 0.9887 - val_loss: 0.0334 - val_acc: 0.9907\n",
      "Epoch 146/150\n",
      " - 198s - loss: 0.0348 - acc: 0.9892 - val_loss: 0.0333 - val_acc: 0.9903\n",
      "Epoch 147/150\n",
      " - 202s - loss: 0.0348 - acc: 0.9891 - val_loss: 0.0335 - val_acc: 0.9907\n",
      "Epoch 148/150\n",
      " - 199s - loss: 0.0341 - acc: 0.9892 - val_loss: 0.0338 - val_acc: 0.9903\n",
      "Epoch 149/150\n",
      " - 203s - loss: 0.0340 - acc: 0.9898 - val_loss: 0.0330 - val_acc: 0.9907\n",
      "Epoch 150/150\n",
      " - 211s - loss: 0.0345 - acc: 0.9890 - val_loss: 0.0326 - val_acc: 0.9907\n",
      "Точность работы на тестовых данных: 99.19%\n",
      "Точность модели на тестовых данных: 99.19%\n"
     ]
    }
   ],
   "source": [
    "#распознавание рукописного текста\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.datasets import mnist#-классификация рукописных цифр\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD #SGD - стохастический градиентный спуск\n",
    "from keras.layers import Flatten, Activation\n",
    "from keras.models import Sequential#модель нейронной сети слои которой соединены друг с другом\n",
    "from keras.layers import Dense#соединение всех нейронов предыдущего уровня со всми нейронами следующего уровня\n",
    "from keras.utils import np_utils#утилиты для работы с массивами\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Размер изображения\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "\n",
    "\n",
    "# Устанавливаем seed для повторяемости результатов\n",
    "np.random.seed(42)\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Преобразование размерности изображений\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# Нормализация данных\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Преобразуем метки в категории\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(75, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.2))#Dropout - предотвращает переобучение\n",
    "#0.2 - нейрон будет отключаться с вероятностью 20%\n",
    "#Оставшиеся нейроны обучаются распознавать признаки без участия соседних\n",
    "\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(100, (5, 5), activation='relu'))\n",
    "\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.2))#Dropout - предотвращает переобучение\n",
    "#0.2 - нейрон будет отключаться с вероятностью 20%\n",
    "#Оставшиеся нейроны обучаются распознавать признаки без участия соседних\n",
    "\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(500, activation='relu'))\n",
    "\n",
    "# Слой регуляризации Dropout\n",
    "model.add(Dropout(0.5))#Dropout - предотвращает переобучение\n",
    "#0.2 - нейрон будет отключаться с вероятностью 20%\n",
    "#Оставшиеся нейроны обучаются распознавать признаки без участия соседних\n",
    "\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Компилируем модель\n",
    "#SGD - стохастический градиентный спуск\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Обучаем сеть\n",
    "# размер минивыборки = 200 элементов, epochs = количество обучений(лучший результат при 150)\n",
    "#20% - проверочная выборка\n",
    "model.fit(X_train, Y_train, batch_size=200, epochs=120, validation_split=0.2, verbose=2)\n",
    "\n",
    "# Оцениваем качество обучения сети на тестовых данных\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "#Сохраняем обученную нейронную сеть в файл\n",
    "\n",
    "# Генерируем описание модели в формате json\n",
    "model_json = model.to_json()\n",
    "# Записываем модель в файл\n",
    "json_file = open(\"mnistreal_model.json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "#Для сохранения данных о весах сети Keras использует формат HDF5\n",
    "model.save_weights(\"mnistreal_model.h5\")\n",
    "\n",
    "#Загружаем обученную нейронную сеть из файла\n",
    "\n",
    "# Загружаем данные об архитектуре сети из файла json\n",
    "json_file = open(\"mnistreal_model.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "# Создаем модель на основе загруженных данных\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# Загружаем веса в модель\n",
    "loaded_model.load_weights(\"mnistreal_model.h5\")\n",
    "\n",
    "#Перед использованием модели, ее обязательно нужно скомпилировать:\n",
    "\n",
    "# Компилируем модель\n",
    "loaded_model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "# Проверяем модель на тестовых данных\n",
    "scores = loaded_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Точность модели на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
